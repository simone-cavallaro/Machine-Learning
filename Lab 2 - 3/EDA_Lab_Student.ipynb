{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Hands-On Lab — Ames Housing Dataset *(Student Notebook)*\n",
    "\n",
    "**Master's in Data Science — LUISS Guido Carli**\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| **Format** | Hands-on practical lab (~90 min) |\n",
    "| **Dataset** | Ames Housing — 1,460 houses, 81 features, target: SalePrice |\n",
    "| **Slides** | EDA_Lecture.pptx — use as reference throughout |\n",
    "| **Goal** | Execute a complete, systematic EDA workflow from raw data to modeling-ready features |\n",
    "\n",
    "### How this notebook works\n",
    "- **Pre-filled cells** → run them as-is (setup, helpers, visualizations)\n",
    "- **TASK cells** → you write the code! Follow the instructions and slide references\n",
    "- ** Hints** → nudge you in the right direction\n",
    "- Tasks are numbered sequentially. Try before looking at the solution notebook!\n",
    "\n",
    "| Step | What | Time | Slides |\n",
    "|------|------|------|--------|\n",
    "| 0 | Setup & Load | 3 min | 2 |\n",
    "| 1 | First Contact — shape, types, sanity | 7 min | 4-6 |\n",
    "| 2 | Data Types — numerical vs categorical | 7 min | 8-9 |\n",
    "| 3 | Summary Statistics — center, spread, shape | 10 min | 11-16 |\n",
    "| 4 | Univariate Analysis — distributions one at a time | 12 min | 18-22 |\n",
    "| 5 | Bivariate Analysis — relationships between pairs | 15 min | 24-29 |\n",
    "| 6 | Multivariate — PCA, pair plots | 8 min | 31-33 |\n",
    "| 7 | Missing Data — patterns & imputation | 10 min | 36-38 |\n",
    "| 8 | Outliers — detection & strategy | 8 min | 40-42 |\n",
    "| 9 | Transformations — log, scaling, encoding | 8 min | 44-46 |\n",
    "| 10 | Wrap-up — checklist & Anscombe | 2 min | 48-53 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0 — Setup & Data Loading `[Slide 2]` 3 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setup complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid', font_scale=1.05, palette='muted')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Color palette\n",
    "NAVY, STEEL, CORAL, GREEN = '#1A3764', '#4682B4', '#E8735A', '#27AE60'\n",
    "\n",
    "print(' Setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1,460 rows × 81 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.00</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.00</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL        65.00     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL        80.00     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL        68.00    11250   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  ...  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003  ...   \n",
       "1       Norm     1Fam     1Story            6            8       1976  ...   \n",
       "2       Norm     1Fam     2Story            7            5       2001  ...   \n",
       "\n",
       "   GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF  \\\n",
       "0           2        548         TA         TA          Y          0   \n",
       "1           2        460         TA         TA          Y        298   \n",
       "2           2        608         TA         TA          Y          0   \n",
       "\n",
       "   OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea PoolQC Fence  \\\n",
       "0           61             0         0           0        0    NaN   NaN   \n",
       "1            0             0         0           0        0    NaN   NaN   \n",
       "2           42             0         0           0        0    NaN   NaN   \n",
       "\n",
       "  MiscFeature  MiscVal MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0         NaN        0      2    2008        WD         Normal    208500  \n",
       "1         NaN        0      5    2007        WD         Normal    181500  \n",
       "2         NaN        0      9    2008        WD         Normal    223500  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Ames Housing dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "ames = fetch_openml(name='house_prices', as_frame=True, parser='auto')\n",
    "df = ames.frame.copy()\n",
    "print(f'Loaded: {df.shape[0]:,} rows × {df.shape[1]} columns')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 — First Contact with the Data `[Slides 4-6]` 7 min\n",
    "\n",
    "> *\"Let the data speak — don't impose assumptions prematurely.\"* — Tukey\n",
    "\n",
    "Before any analysis: **understand what you have**. Shape, types, basic sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) \n",
      " 3619902 \n",
      " Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt'],\n",
      "      dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# TASK 1 \n",
    "# Print the shape, memory usage, and first 20 column names of df\n",
    "# Hint: Use df.shape, df.memory_usage(deep=True).sum(), df.columns[:20]\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "print(df.shape,\"\\n\" ,df.memory_usage(deep=True).sum(),'\\n', df.columns[:20] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0 \n",
      " Number of unique item in the 'Id' column: 1460\n"
     ]
    }
   ],
   "source": [
    "# TASK 2 \n",
    "# Check for duplicate rows and verify the Id column is unique\n",
    "# Hint: df.duplicated().sum() and df['Id'].nunique()\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "print(\"Number of duplicated rows:\",df.duplicated().sum(), '\\n',\"Number of unique item in the 'Id' column:\", df['Id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1460.00\n",
       "mean    180921.20\n",
       "std      79442.50\n",
       "min      34900.00\n",
       "25%     129975.00\n",
       "50%     163000.00\n",
       "75%     214000.00\n",
       "max     755000.00\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 3 \n",
    "# Print min, max, mean, median, and missing count for SalePrice\n",
    "# Hint: Use df['SalePrice'].min(), .max(), .mean(), .median(), .isnull().sum()\n",
    "#\n",
    "# YOUR CODE HERE\n",
    "df[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** Mean > Median → right-skewed distribution (expensive homes pull the mean up). See `[Slide 11]` for why this matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 — Data Types `[Slides 8-9]` 7 min\n",
    "\n",
    "Choosing the right visualization and statistical test **depends entirely on data type**.\n",
    "\n",
    "| | Continuous | Discrete | Nominal | Ordinal |\n",
    "|---|---|---|---|---|\n",
    "| Example | SalePrice | Bedrooms | BldgType | OverallQual |\n",
    "| Plot | Histogram | Bar | Count plot | Ordered bar |\n",
    "| Correlation | Pearson/Spearman | Spearman | Chi² | Spearman |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4 \n",
    "# Count dtypes, separate numerical vs categorical columns, remove 'Id' from num_cols\n",
    "# Hint: df.dtypes.value_counts(), df.select_dtypes(include=[np.number]).columns\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 5 \n",
    "# Create 3 side-by-side plots: histogram for GrLivArea, bar for FullBath, barh for MSZoning\n",
    "# Hint: plt.subplots(1,3), .hist(), .value_counts().plot.bar(), .value_counts().plot.barh()\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Pandas dtype ≠ statistical type!** A zip code stored as `int64` is categorical. Always verify with domain knowledge. See `[Slide 9]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Summary Statistics `[Slides 11-16]` 10 min\n",
    "\n",
    "Three pillars: **center** (mean, median, mode), **spread** (std, IQR, CV), **shape** (skewness, kurtosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 6 \n",
    "# Compute mean, median, mode of SalePrice. Plot histogram with mean/median lines + box plot. [Slide 11]\n",
    "# Hint: price.mean(), .median(), .mode()[0]. Use ax.axvline() for vertical lines. ax.boxplot() for box plot\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 7 \n",
    "# Compute Mean, Std, IQR, Range, and CV% for 5 features. Which has highest relative variability?\n",
    "# Hint: IQR = .quantile(0.75) - .quantile(0.25), CV = std/mean * 100\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 8 \n",
    "# Compute skewness and kurtosis for all numerical features. How many have |skew| > 1?\n",
    "# Hint: df[num_cols].skew(), .kurtosis(). Flag with .abs() > 1\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 9 \n",
    "# Run df.describe() on the first 10 numerical columns. Transpose the result for readability.\n",
    "# Hint: df[num_cols[:10]].describe().T\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 — Univariate Analysis `[Slides 18-22]` 12 min\n",
    "\n",
    "Examine **one variable at a time**. Four views for numerical, two for categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Numerical: Four Views of SalePrice `[Slide 18]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 10 \n",
    "# Create a 2×2 grid showing SalePrice as: histogram, KDE, box plot, violin plot [Slide 18]\n",
    "# Hint: plt.subplots(2,2). Use .hist(), .plot.kde(), ax.boxplot(vert=False), ax.violinplot(vert=False)\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Bin Size Effect `[Slide 19]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 11 \n",
    "# Plot SalePrice histograms with 5, 20, 50, and 200 bins side by side. Which reveals the most structure?\n",
    "# Hint: plt.subplots(1,4), loop over [5, 20, 50, 200]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 QQ-Plot: Testing Normality `[Slide 21]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 12 \n",
    "# Create QQ-plots for SalePrice (original) and log(SalePrice). Run Shapiro-Wilk on both.\n",
    "# Hint: stats.probplot(data, plot=ax). stats.shapiro(sample). Use np.log1p() for log(x+1)\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Categorical Features `[Slide 22]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 13 \n",
    "# Plot: top 10 neighborhoods (barh), OverallQual distribution (bar), cardinality of all categoricals\n",
    "# Hint: value_counts().head(10).plot.barh(), nunique().sort_values()\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5 — Bivariate Analysis `[Slides 24-29]` 15 min\n",
    "\n",
    "Relationships between **pairs** of variables. This is where modeling insights emerge.\n",
    "\n",
    "### 5.1 Numerical × Numerical: Scatter + Pearson `[Slide 24]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 14 \n",
    "# Compute correlation of all numerical features with SalePrice. Show top 8 positive and top 3 negative.\n",
    "# Hint: df[num_cols].corrwith(df['SalePrice']).sort_values(ascending=False)\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 15 \n",
    "# Scatter plots with regression line for top 4 predictors of SalePrice\n",
    "# Hint: np.polyfit() for regression, np.polyval() to evaluate. ax.scatter() + ax.plot()\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Correlation Heatmap + Spearman `[Slides 25-26]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 16 \n",
    "# Create correlation heatmap (lower triangle) for top 8 features. Detect multicollinearity (r > 0.8).\n",
    "# Hint: np.triu() for mask, sns.heatmap(mask=mask, annot=True). Loop over pairs to find |r| > 0.8\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 17 \n",
    "# Compare Pearson vs Spearman for each top feature. Which features show non-linear relationships?\n",
    "# Hint: df[feat].corr(df['SalePrice'], method='pearson') vs method='spearman'\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Categorical × Numerical: ANOVA `[Slides 27-28]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 18 \n",
    "# Box plots: SalePrice by ExterQual (ordered) and by top 8 Neighborhoods. Run ANOVA on ExterQual groups.\n",
    "# Hint: sns.boxplot(order=...). stats.f_oneway(*groups) for ANOVA. [Slides 27-28]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Categorical × Categorical: Chi² `[Slide 29]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 19 \n",
    "# Create contingency table for MSZoning × BldgType. Run chi-squared test. Heatmap observed vs expected.\n",
    "# Hint: pd.crosstab(). stats.chi2_contingency(ct) returns chi2, p, dof, expected. [Slide 29]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 — Multivariate Analysis `[Slides 31-33]` 8 min\n",
    "\n",
    "### 6.1 Pair Plot `[Slide 31]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 20 \n",
    "# Pair plot of SalePrice, GrLivArea, YearBuilt, TotalBsmtSF, colored by quality bins\n",
    "# Hint: pd.cut() to bin OverallQual into 4 groups, sns.pairplot(hue=...)\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 PCA `[Slides 32-33]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 21 \n",
    "# PCA: scale data → fit 10 components → plot 2D projection colored by SalePrice + scree plot\n",
    "# Hint: StandardScaler().fit_transform(), PCA(n_components=10).fit_transform(). Scree: cumsum of explained_variance_ratio_\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 — Missing Data `[Slides 36-38]` 10 min\n",
    "\n",
    "> **The pattern of missingness contains information!** — See Rubin's taxonomy `[Slide 36]`\n",
    "\n",
    "| Type | Mechanism | Strategy |\n",
    "|------|-----------|----------|\n",
    "| **MCAR** | Independent of all data | Drop rows |\n",
    "| **MAR** | Depends on *observed* data | Impute |\n",
    "| **MNAR** | Depends on *missing value itself* | Domain knowledge |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 22 \n",
    "# Count features with missing values. Show top 10 with their % missing.\n",
    "# Hint: df.isnull().sum() / len(df) * 100. Sort descending.\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 23 \n",
    "# Bar chart of top 12 missing features. Heatmap of missingness patterns. What co-occurrence patterns do you see?\n",
    "# Hint: df[cols].isnull().astype(int) for the matrix. sns.heatmap() with binary colormap. [Slide 37]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 24 \n",
    "# Compare Mean, Median, and KNN imputation on LotFrontage. Which preserves the distribution best?\n",
    "# Hint: KNNImputer(n_neighbors=5) from sklearn.impute. Use nearby features (LotArea, GrLivArea). [Slide 38]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8 — Outlier Detection `[Slides 40-42]` 8 min\n",
    "\n",
    "### 8.1 IQR Method & Z-Score `[Slide 40]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 25 \n",
    "# Write IQR and Z-score outlier functions. Apply to GrLivArea. Scatter plot showing outliers in red.\n",
    "# Hint: IQR: Q1-1.5*IQR, Q3+1.5*IQR. Z-score: |z| > 3. [Slide 40]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Isolation Forest `[Slide 41]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 26 \n",
    "# Isolation Forest on GrLivArea × SalePrice (contamination=0.02). Scatter normal vs outlier.\n",
    "# Hint: IsolationForest(contamination=0.02). fit_predict() returns 1 (normal) or -1 (outlier). [Slide 41]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9 — Data Transformations `[Slides 44-46]` 8 min\n",
    "\n",
    "### 9.1 Log Transform `[Slide 44]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 27 \n",
    "# Apply log1p transform to SalePrice, LotArea, GrLivArea. Show before/after with skewness values.\n",
    "# Hint: np.log1p(). .skew() for skewness. Side-by-side histograms. [Slide 44]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Feature Scaling `[Slide 45]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 28 \n",
    "# Apply 4 scalers to GrLivArea. Side-by-side histograms. Which preserves shape? Which normalizes?\n",
    "# Hint: StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer from sklearn.preprocessing. [Slide 45]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Encoding `[Slide 46]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 29 \n",
    "# Apply label encoding to ExterQual, one-hot to BldgType, target encoding to Neighborhood.\n",
    "# Hint: .map(dict) for label. pd.get_dummies() for one-hot. .groupby().mean() for target. [Slide 46]\n",
    "#\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10 — Wrap-up `[Slides 48-53]` 2 min\n",
    "\n",
    "### Anscombe's Quartet — Why We ALWAYS Visualize `[Slide 48]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anscombe's Quartet \n",
    "anscombe = sns.load_dataset('anscombe')\n",
    "\n",
    "print('Four datasets with IDENTICAL statistics:')\n",
    "for ds in ['I', 'II', 'III', 'IV']:\n",
    " d = anscombe[anscombe['dataset'] == ds]\n",
    " print(f' Dataset {ds}: mean(x)={d[\"x\"].mean():.1f}, mean(y)={d[\"y\"].mean():.2f}, '\n",
    " f'r={d[\"x\"].corr(d[\"y\"]):.3f}')\n",
    "\n",
    "g = sns.lmplot(data=anscombe, x='x', y='y', col='dataset', col_wrap=2,\n",
    " height=3, aspect=1.3, scatter_kws={'s': 40, 'color': STEEL},\n",
    " line_kws={'color': 'red', 'lw': 2})\n",
    "g.fig.suptitle('Same Statistics → Completely Different Patterns!', fontweight='bold', color=CORAL, fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "print('\\n LESSON: Never skip visualization. Statistics can lie. [Slide 48]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Checklist — Before You Model `[Slide 53]`\n",
    "\n",
    "Run through this checklist before starting any modeling:\n",
    "\n",
    "- [ ] Shape, types, and column names understood?\n",
    "- [ ] Missing value patterns identified and strategy decided?\n",
    "- [ ] Every feature's distribution examined?\n",
    "- [ ] Outliers detected and handling strategy chosen?\n",
    "- [ ] Feature-target correlations verified?\n",
    "- [ ] Multicollinearity addressed?\n",
    "- [ ] Transformations applied (log, scaling)?\n",
    "- [ ] Categorical features encoded?\n",
    "- [ ] All findings documented?\n",
    "\n",
    "> **Only when all boxes are checked → proceed to modeling.**\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of what we did today\n",
    "\n",
    "| Step | What | Key Finding (Ames) |\n",
    "|------|------|--------------------|\n",
    "| 1 | First contact | 1,460 × 81, no duplicates |\n",
    "| 2 | Data types | 38 numerical, 43 categorical |\n",
    "| 3 | Summary stats | SalePrice right-skewed (skew ≈ 1.9) |\n",
    "| 4 | Univariate | Many features highly skewed; QQ confirms non-normality |\n",
    "| 5 | Bivariate | OverallQual (r=0.79) and GrLivArea (r=0.71) top predictors |\n",
    "| 6 | Multivariate | 6 PCs capture 90% variance; quality separates clusters |\n",
    "| 7 | Missing data | 19 features missing; PoolQC = 99.5% (no pool, not error) |\n",
    "| 8 | Outliers | 2 extreme GrLivArea points; Isolation Forest detects multivariate |\n",
    "| 9 | Transforms | Log reduces skew from 1.9 → 0.1; RobustScaler for outliers |\n",
    "\n",
    "---\n",
    "*End of Hands-On Lab — LUISS Guido Carli*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Well done\n",
    "You've completed the full EDA pipeline. Compare your solutions with the complete notebook to check your work.\n",
    "\n",
    "**Key takeaway:** This workflow (Steps 1→9) works on **any** tabular dataset. Memorize the structure, not the code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
